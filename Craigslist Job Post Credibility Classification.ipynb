{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3d466af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zhangtang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zhangtang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zhangtang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 1. 导入库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "521bac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 读取数据\n",
    "df = pd.read_csv('/Users/zhangtang/Documents/Social Media and Text Analytics/Group Project/All combined data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7d83d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 文本清洗\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['cleaned_description'] = df['description'].fillna('').apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4da25943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 随机划分 Validation Set (100条)\n",
    "df_train_test, df_val = train_test_split(df, test_size=150, random_state=42, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3737739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 特征工程 (fit on train_test, transform on both)\n",
    "\n",
    "# 文本TF-IDF特征\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=3)\n",
    "X_text_train_test = vectorizer.fit_transform(df_train_test['cleaned_description'])\n",
    "X_text_val = vectorizer.transform(df_val['cleaned_description'])\n",
    "\n",
    "# employment_type OneHot特征\n",
    "ohe = OneHotEncoder(sparse_output=True)\n",
    "X_employment_type_train_test = ohe.fit_transform(df_train_test['employment_type'].fillna('unknown').values.reshape(-1, 1))\n",
    "X_employment_type_val = ohe.transform(df_val['employment_type'].fillna('unknown').values.reshape(-1, 1))\n",
    "\n",
    "# 手工数值特征\n",
    "\n",
    "def build_numeric_features(sub_df):\n",
    "    has_contact_info = sub_df['contact_info'].notna().astype(int)\n",
    "\n",
    "    def is_company_email(contact):\n",
    "        if pd.isna(contact):\n",
    "            return 0\n",
    "        contact = contact.lower()\n",
    "        if any(domain in contact for domain in ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com']):\n",
    "            return 0\n",
    "        if '@' in contact:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    company_email = sub_df['contact_info'].apply(is_company_email)\n",
    "\n",
    "    def has_phone(contact):\n",
    "        if pd.isna(contact):\n",
    "            return 0\n",
    "        numbers = re.findall(r'\\d{7,}', contact)\n",
    "        return int(len(numbers) > 0)\n",
    "\n",
    "    has_phone_number = sub_df['contact_info'].apply(has_phone)\n",
    "    has_compensation = sub_df['compensation'].apply(lambda x: int(str(x).strip().lower() != 'compensation:' and pd.notna(x)))\n",
    "    has_company_name = sub_df['company'].notna().astype(int)\n",
    "    word_count = sub_df['description'].fillna('').apply(lambda x: len(str(x).split()))\n",
    "    exclamation_count = sub_df['description'].fillna('').apply(lambda x: str(x).count('!'))\n",
    "\n",
    "    X_numeric = np.vstack([\n",
    "        has_contact_info,\n",
    "        company_email,\n",
    "        has_phone_number,\n",
    "        has_compensation,\n",
    "        has_company_name,\n",
    "        word_count,\n",
    "        exclamation_count\n",
    "    ]).T\n",
    "\n",
    "    return X_numeric\n",
    "\n",
    "X_numeric_train_test = build_numeric_features(df_train_test)\n",
    "X_numeric_val = build_numeric_features(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95520f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 特征组合与标签\n",
    "df_train_test.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train_test = hstack([X_text_train_test, X_numeric_train_test, X_employment_type_train_test])\n",
    "X_val = hstack([X_text_val, X_numeric_val, X_employment_type_val])\n",
    "\n",
    "X_train_test = csr_matrix(X_train_test)\n",
    "X_val = csr_matrix(X_val)\n",
    "\n",
    "y_train_test = df_train_test['label']\n",
    "y_val = df_val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc477733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 再将 train_test 分成 Train 和 Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_test, y_train_test, test_size=0.2, random_state=42, stratify=y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96a50773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 定义模型\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'SVM (Linear Kernel)': SVC(kernel='linear', probability=True),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28b03dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 训练与验证\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': accuracy_score(y_test, y_pred_test),\n",
    "        'Test Precision': precision_score(y_test, y_pred_test),\n",
    "        'Test F1': f1_score(y_test, y_pred_test),\n",
    "        'Validation Accuracy': accuracy_score(y_val, y_pred_val)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22c92bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Test Accuracy  Test Precision   Test F1  \\\n",
      "2  SVM (Linear Kernel)           0.99        0.985294  0.992593   \n",
      "0  Logistic Regression           0.96        0.943662  0.971014   \n",
      "1        Random Forest           0.95        0.930556  0.964029   \n",
      "3          Naive Bayes           0.74        0.720430  0.837500   \n",
      "\n",
      "   Validation Accuracy  \n",
      "2             0.986667  \n",
      "0             0.980000  \n",
      "1             0.973333  \n",
      "3             0.793333  \n"
     ]
    }
   ],
   "source": [
    "# 10. 输出比较\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Validation Accuracy', ascending=False)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
